import os, json, tempfile
import streamlit as st
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.retrievers import EnsembleRetriever
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader # PDF ë¡œë”
from langchain.text_splitter import RecursiveCharacterTextSplitter # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")


# --- í•¨ìˆ˜ ì •ì˜ ---

# 1) PDF íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ (ì‹ ê·œ ì¶”ê°€)
def process_pdf(uploaded_file):
    # Streamlitì˜ UploadedFile ê°ì²´ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ê²½ë¡œë¥¼ ì–»ìŠµë‹ˆë‹¤.
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œ ë¡œë“œ
    loader = PyPDFLoader(tmp_file_path)
    docs_from_pdf = loader.load()

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(tmp_file_path)

    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°(Splitter)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = text_splitter.split_documents(docs_from_pdf)
    return split_docs

# 2) ì•™ìƒë¸” Retriever êµ¬ì„±(BM25 + FAISS)
# @st.cache_data # ë¦¬ì†ŒìŠ¤ê°€ í° ê²½ìš° ìºì‹±í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
def build_ensemble_retriever(docs):
    texts = [d.page_content for d in docs]
    metadatas = [d.metadata for d in docs]

    bm25 = BM25Retriever.from_texts(texts, metadatas=metadatas); bm25.k = 2
    embedding = HuggingFaceEmbeddings(model_name="distiluse-base-multilingual-cased-v1")
    faiss_store = FAISS.from_texts(texts, embedding, metadatas=metadatas)
    faiss = faiss_store.as_retriever(search_kwargs={"k": 2})
    return EnsembleRetriever(retrievers=[bm25, faiss], weights=[0.3, 0.7])

# 3) OpenAI LLM ì´ˆê¸°í™”(ìºì‹œ)
@st.cache_resource(show_spinner=False)
def load_openai_llm(model_name: str = "gpt-4o-mini", temperature: float = 0.0):
    api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•˜ì„¸ìš”.")
    return ChatOpenAI(model=model_name, temperature=temperature, api_key=api_key)

# 4) ê²€ìƒ‰ í•¨ìˆ˜(ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
def search(query: str, retriever):
    return retriever.invoke(query)

# 5) RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„±
def build_prompt(query: str, docs):
    lines = ["ì•„ë˜ 'ìë£Œ'ë§Œ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°íˆ ë‹µí•˜ì„¸ìš”.",
             "- ìë£Œ ë°– ì •ë³´ë¥¼ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.",
             "- ë‹µí•  ìˆ˜ ì—†ìœ¼ë©´ 'ì œê³µëœ ë¬¸ì„œì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³  ë§í•˜ì„¸ìš”.\n",
             f"ì§ˆë¬¸:\n{query}\n",
             "ìë£Œ:"]
    for i, d in enumerate(docs, 1):
        lines.append(f"[ë¬¸ì„œ{i}] (source: page {d.metadata.get('page', 'N/A')})\n{d.page_content}\n")
    lines.append("ë‹µë³€:")
    return "\n".join(lines)

# 6) OpenAIë¡œ ë‹µë³€ ìƒì„±
def generate_with_llm(llm: ChatOpenAI, prompt: str) -> str:
    resp = llm.invoke(prompt)
    return resp.content.strip()

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ğŸ¤– ChatPDF", page_icon="ğŸ“„", layout="centered")
    st.title("ğŸ¤– ChatPDF")
    st.markdown("---")

    # LLM ëª¨ë¸ ì´ˆê¸°í™”
    try:
        llm = load_openai_llm()
    except RuntimeError as e:
        st.error(str(e))
        st.stop()

    # ì‚¬ì´ë“œë°”ì— PDF ì—…ë¡œë” ì¶”ê°€
    with st.sidebar:
        st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ì—¬ê¸°ì— PDFë¥¼ ë“œë¡­í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="pdf")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "retriever" not in st.session_state:
        st.session_state.retriever = None

    # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œë§Œ ì²˜ë¦¬
    if uploaded_file:
        #ì´ì „ì— ì²˜ë¦¬í•œ íŒŒì¼ê³¼ ë‹¤ë¥¸ íŒŒì¼ì´ë©´ ìƒˆë¡œ ì²˜ë¦¬
        if st.session_state.get("processed_file_name") != uploaded_file.name:
            with st.spinner("PDF íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                docs = process_pdf(uploaded_file)
                st.session_state.retriever = build_ensemble_retriever(docs)
                st.session_state.processed_file_name = uploaded_file.name
                st.session_state.messages = [] # ìƒˆ íŒŒì¼ì´ë¯€ë¡œ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
            st.success(f"'{uploaded_file.name}' íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”.")

    # ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    if user_input:
        if not st.session_state.retriever:
            st.error("ë¨¼ì € ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        st.chat_message("user").markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})

        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            docs = search(user_input.strip(), st.session_state.retriever)

            if not docs:
                answer = "ì—…ë¡œë“œëœ PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            else:
                prompt = build_prompt(user_input.strip(), docs)
                answer = generate_with_llm(llm, prompt)

        with st.chat_message("assistant"):
            st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})

        with st.expander("ğŸ” ì‚¬ìš©í•œ ìë£Œ(ê²€ìƒ‰ ê²°ê³¼) ë³´ê¸°", expanded=False):
            if not docs:
                st.markdown("_ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ_")
            else:
                for d in docs:
                    st.markdown(f"**[Page {d.metadata.get('page', 'N/A')}]**\n\n{d.page_content}")
    
    elif not uploaded_file:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

# --- ì•± ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ---
if __name__ == "__main__":
    main()